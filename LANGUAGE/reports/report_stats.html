<!-- author: d0hm4t06 3lv15 d0p91m4 -->


<html>
  <head>
    <!--refreshstart-->
    
      <!--refreshstop-->
      <link rel=stylesheet type=text/css href="./styles.css">
	<title>pypreprocess report</title>
  </head>

  <body>
    <object data="report.html"></object>
    <h2>Group GLM for HCP fMRI LANGUAGE task</h2>
    <font color=red>REPORTS ONLY WORK ON FIREFOX!</font><br/><br/>
    Started: 13:55:56 Sat 16 Nov 2013
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ended: 13:57:19 Sat 16 Nov 2013
    <br clear="all"/>   
    <hr/>

    <b>Methods used</b><br/><br/>
    
    GLM and Statistical Inference have been done using the <i>scripts/hcp_preproc_and_analysis.py</i> script, powered by <a href="http://nipy.sourceforge.net/nipy/stable/index.html">nipy</a>. Statistic images have been thresholded at Z>3.0 voxel-level.
    

    <br/><br/>
    <div id="sourcecode">
      <!-- create sourcecode anchor (a) for toggling text between `Hide` and `View`states -->
      <a class="sourcecodeanchor" href="#"><blink>View source code for script scripts/hcp_preproc_and_analysis.py</blink></a>
      <code class="hidden"><br/><ol><pre><li>"""</li><li>:Synopsis: preprocessing and/or analysis of HCP task fMRI data</li><li>:Author: DOHMATOB Elvis Dopgima <gmdopp@gmail.com> <elvis.dohmatob@inria.fr></li><li></li><li>"""</li><li></li><li>import os</li><li>import sys</li><li>import re</li><li>import glob</li><li>import numpy as np</li><li>import nibabel</li><li>import commands</li><li>from nipy.modalities.fmri.glm import FMRILinearModel</li><li>from nipy.labs.mask import intersect_masks</li><li>from pypreprocess.nipype_preproc_spm_utils import (SubjectData,</li><li>                                                   _do_subject_realign,</li><li>                                                   _do_subject_smooth,</li><li>                                                   do_subject_preproc)</li><li>from pypreprocess.io_utils import load_specific_vol</li><li>from pypreprocess.fsl_to_nipy import (read_design_fsl_design_file,</li><li>                                      make_dmtx_from_timing_files,</li><li>                                      _insert_directory_in_file_name)</li><li>from pypreprocess.reporting.glm_reporter import generate_subject_stats_report</li><li>from pypreprocess.reporting.base_reporter import (ProgressReport,</li><li>                                                  pretty_time)</li><li>from joblib import Parallel, delayed, Memory</li><li></li><li></li><li>def _do_fmri_distortion_correction(fmri_files, subject_data_dir,</li><li>                                   subject_output_dir,</li><li>                                   subject_id,</li><li>                                   task_id,</li><li></li><li>                                   # i'm unsure of the readout time,</li><li>                                   # but this is constant across both PE</li><li>                                   # directions and so can be scaled to 1</li><li>                                   # (or any other nonzero float)</li><li>                                   readout_time=.01392,</li><li>                                   do_report=False</li><li>                                   ):</li><li>    """</li><li>    Function to undistort task fMRI data for a given HCP subject.</li><li></li><li>    """</li><li></li><li>    # prepare for smart caching</li><li>    mem = Memory(os.path.join(subject_output_dir, "cache_dir"))</li><li></li><li>    acq_params = [[1, 0, 0, readout_time], [-1, 0, 0, readout_time]]</li><li>    acq_params_file = os.path.join(subject_output_dir,</li><li>                                   "b0_acquisition_params.txt")</li><li>    np.savetxt(acq_params_file, acq_params, fmt='%f')</li><li></li><li>    fieldmap_files = [os.path.join(</li><li>            subject_data_dir,</li><li>            "unprocessed/3T/tfMRI_%s_%s/%s_3T_SpinEchoFieldMap_"</li><li>            "%s.nii.gz" % (task_id, direction, subject_id, direction))</li><li>                      for direction in ["LR", "RL"]]</li><li>    assert len(fieldmap_files) == 2</li><li></li><li>    # fslroi</li><li>    zeroth_fieldmap_files = []</li><li>    for fieldmap_file in fieldmap_files:</li><li>        if not os.path.isfile(fieldmap_file):</li><li>            print "Can't find fieldmap file %s; skipping subject %s" % (</li><li>                fieldmap_file, subject_id)</li><li>            return</li><li></li><li>        # peel 0th volume of each fieldmap</li><li>        zeroth_fieldmap_file = os.path.join(</li><li>            subject_output_dir, "0th_%s" % os.path.basename(</li><li>                fieldmap_file))</li><li>        fslroi_cmd = "fsl5.0-fslroi %s %s 0 1" % (</li><li>            fieldmap_file, zeroth_fieldmap_file)</li><li>        print "\r\nExecuting %s ..." % fslroi_cmd</li><li>        print mem.cache(commands.getoutput)(fslroi_cmd)</li><li></li><li>        zeroth_fieldmap_files.append(zeroth_fieldmap_file)</li><li></li><li>    # merge the 0th volume of each fieldmap</li><li>    merged_zeroth_fieldmap_file = os.path.join(</li><li>        subject_output_dir, "merged_with_other_direction_%s" % (</li><li>            os.path.basename(zeroth_fieldmap_files[0])))</li><li>    fslmerge_cmd = "fsl5.0-fslmerge -t %s %s %s" % (</li><li>        merged_zeroth_fieldmap_file, zeroth_fieldmap_files[0],</li><li>        zeroth_fieldmap_files[1])</li><li>    print "\r\nExecuting %s ..." % fslmerge_cmd</li><li>    print mem.cache(commands.getoutput)(fslmerge_cmd)</li><li></li><li>    # do topup (learn distortion model)</li><li>    topup_results_basename = os.path.join(subject_output_dir,</li><li>                                          "topup_results")</li><li>    topup_cmd = (</li><li>        "fsl5.0-topup --imain=%s --datain=%s --config=b02b0.cnf "</li><li>        "--out=%s" % (merged_zeroth_fieldmap_file, acq_params_file,</li><li>                      topup_results_basename))</li><li>    print "\r\nExecuting %s ..." % topup_cmd</li><li>    print mem.cache(commands.getoutput)(topup_cmd)</li><li></li><li>    # apply learn deformations to absorb distortion</li><li>    dc_fmri_files = []</li><li>    realignment_parameters = []</li><li>    sbref_files = [os.path.join(subject_data_dir,</li><li>                                ("unprocessed/3T/tfMRI_%s_%s/%s_"</li><li>                                 "3T_tfMRI_%s_%s_SBRef.nii.gz") % (</li><li>                task_id, direction, subject_id, task_id, direction))</li><li>                   for direction in ["LR", "RL"]]</li><li>    for index in xrange(2):</li><li>        # merge SBRef + task BOLD for current PE direction</li><li>        fourD_plus_sbref = os.path.join(</li><li>            subject_output_dir, "sbref_plus_" + os.path.basename(</li><li>                fmri_files[index]))</li><li>        fslmerge_cmd = "fsl5.0-fslmerge -t %s %s %s" % (</li><li>            fourD_plus_sbref, sbref_files[index], fmri_files[index])</li><li>        print "\r\nExecuting %s ..." % fslmerge_cmd</li><li>        print mem.cache(commands.getoutput)(fslmerge_cmd)</li><li></li><li>        # realign task BOLD to SBRef</li><li>        subject_data = _do_subject_realign(SubjectData(</li><li>                func=fourD_plus_sbref, output_dir=subject_output_dir),</li><li>                                           do_report=do_report</li><li>                                           )</li><li>        rfourD_plus_sbref = subject_data.func</li><li>        realignment_parameters.append(np.loadtxt(</li><li>                getattr(subject_data, "realignment_parameters"))[1:, ...])</li><li></li><li>        # apply topup to realigned images</li><li>        dc_rfourD_plus_sbref = os.path.join(</li><li>            subject_output_dir, "dc" + os.path.basename(</li><li>                rfourD_plus_sbref))</li><li>        applytopup_cmd = (</li><li>            "fsl5.0-applytopup --imain=%s --verbose --inindex=%i "</li><li>            "--topup=%s --out=%s --datain=%s --method=jac" % (</li><li>                rfourD_plus_sbref, index + 1, topup_results_basename,</li><li>                dc_rfourD_plus_sbref, acq_params_file))</li><li>        print "\r\nExecuting %s ..." % applytopup_cmd</li><li>        print mem.cache(commands.getoutput)(applytopup_cmd)</li><li></li><li>        # recover undistored task BOLD</li><li>        dc_rfmri_file = dc_rfourD_plus_sbref.replace("sbref_plus_", "")</li><li>        fslroi_cmd = "fsl5.0-fslroi %s %s 1 -1" % (</li><li>            dc_rfourD_plus_sbref, dc_rfmri_file)</li><li>        print "\r\nExecuting %s ..." % fslroi_cmd</li><li>        print mem.cache(commands.getoutput)(fslroi_cmd)</li><li></li><li>        # sanity tricks</li><li>        if dc_rfmri_file.endswith(".nii"):</li><li>            dc_rfmri_file = dc_rfmri_file + ".gz"</li><li></li><li>        dc_fmri_files.append(dc_rfmri_file)</li><li></li><li>    return dc_fmri_files, realignment_parameters</li><li></li><li></li><li>def run_suject_level1_glm(subject_data_dir, subject_output_dir, task_id,</li><li>                          readout_time=.01392,  # seconds</li><li>                          tr=.72,</li><li>                          do_preproc=False,</li><li>                          do_realign=False,</li><li>                          do_normalize=False,</li><li>                          fwhm=0.,</li><li>                          do_report=False,</li><li>                          hrf_model="Canonical with Derivative",</li><li>                          drift_model="Cosine",</li><li>                          hfcut=100,</li><li>                          regress_motion=True,</li><li>                          slicer='y',</li><li>                          cut_coords=6,</li><li>                          threshold=3.,</li><li>                          cluster_th=15</li><li>                          ):</li><li>    """</li><li>    Function to do preproc + analysis for a single HCP subject (task fMRI)</li><li></li><li>    """</li><li></li><li>    # sanitize subject data_dir</li><li>    subject_id = int(os.path.basename(subject_data_dir))</li><li>    subject_data_dir = os.path.abspath(subject_data_dir)</li><li>    _subject_data_dir = os.path.join(subject_data_dir,</li><li>                                     "MNINonLinear/Results/")</li><li></li><li>    add_regs_files = None</li><li></li><li>    if do_preproc:</li><li>        if not os.path.exists(subject_output_dir):</li><li>            os.makedirs(subject_output_dir)</li><li></li><li>        # glob fmri files</li><li>        fmri_files = [os.path.join(</li><li>                subject_data_dir,</li><li>                "unprocessed/3T/tfMRI_%s_%s/%s_3T_tfMRI_%s_%s.nii.gz" % (</li><li>                    task_id, direction, subject_id,</li><li>                    task_id, direction))</li><li>                          for direction in ["LR", "RL"]]</li><li>        assert len(fmri_files) == 2</li><li></li><li>        # glob anat file</li><li>        anat_file = os.path.join(subject_data_dir,</li><li>                                 "T1w/T1w_acpc_dc_restore_brain.nii.gz")</li><li>        # assert os.path.isfile(anat_file)</li><li>        if not os.path.isfile(anat_file):</li><li>            anat_file = None</li><li></li><li>        # distortion correction ?</li><li>        dc_output = _do_fmri_distortion_correction(</li><li>            fmri_files, subject_data_dir,</li><li>            subject_output_dir,</li><li>            subject_id, task_id,</li><li>            readout_time=readout_time,</li><li>            do_report=do_report</li><li>            )</li><li>        if dc_output is None:</li><li>            return</li><li>        else:</li><li>            fmri_files, realignment_parameters = dc_output</li><li></li><li>        # preprocess the data</li><li>        preproc_subject_data = do_subject_preproc(SubjectData(</li><li>                func=fmri_files, anat=anat_file,</li><li>                output_dir=subject_output_dir),</li><li>                                                  do_realign=True,</li><li>                                                  do_normalize=do_normalize,</li><li>                                                  fwhm=fwhm,</li><li>                                                  do_report=do_report</li><li>                                                  )</li><li>        fmri_files = preproc_subject_data.func</li><li>        n_motion_regressions = 6</li><li>        if do_realign and regress_motion:</li><li>            add_regs_files = realignment_parameters</li><li>    else:</li><li>        n_motion_regressions = 12</li><li></li><li>        # glob fmri files</li><li>        fmri_files = []</li><li>        for direction in ['LR', 'RL']:</li><li>            fmri_file = os.path.join(</li><li>                _subject_data_dir, "tfMRI_%s_%s/tfMRI_%s_%s.nii.gz" % (</li><li>                    task_id, direction, task_id, direction))</li><li>            if not os.path.isfile(fmri_file):</li><li>                print "Can't find task fMRI file %s; skipping subject %s" % (</li><li>                    fmri_file, subject_id)</li><li>                return</li><li>            else:</li><li>                fmri_files.append(fmri_file)</li><li></li><li>        # glob movement confounds</li><li>        if regress_motion:</li><li>            add_regs_files = [os.path.join(_subject_data_dir,</li><li>                                           "tfMRI_%s_%s" % (</li><li>                        task_id, direction),</li><li>                                           "Movement_Regressors.txt")</li><li>                              for direction in ["LR", "RL"]]</li><li></li><li>        # smooth images</li><li>        if np.sum(fwhm) > 0:</li><li>            print "Smoothing fMRI data (fwhm = %s)..." % fwhm</li><li>            fmri_files = _do_subject_smooth(SubjectData(</li><li>                    func=fmri_files, output_dir=subject_output_dir),</li><li>                                            fwhm=fwhm,</li><li>                                            do_report=False</li><li>                                            ).func</li><li>            print "... done.\r\n"</li><li></li><li>    # sanitize subject_output_dir</li><li>    if not os.path.exists(subject_output_dir):</li><li>        os.makedirs(subject_output_dir)</li><li></li><li>    # chronometry</li><li>    stats_start_time = pretty_time()</li><li></li><li>    # merged lists</li><li>    paradigms = []</li><li>    frametimes_list = []</li><li>    design_matrices = []</li><li>    # fmri_files = []</li><li>    n_scans = []</li><li>    for direction, direction_index in zip(['LR', 'RL'], xrange(2)):</li><li>        # glob the design file</li><li>        design_file = os.path.join(_subject_data_dir, "tfMRI_%s_%s" % (</li><li>                task_id, direction),</li><li>                                   "tfMRI_%s_%s_hp200_s4_level1.fsf" % (</li><li>                task_id, direction))</li><li>        if not os.path.isfile(design_file):</li><li>            print "Can't find design file %s; skipping subject %s" % (</li><li>                design_file, subject_id)</li><li>            return</li><li></li><li>        # read the experimental setup</li><li>        print "Reading experimental setup from %s ..." % design_file</li><li>        fsl_condition_ids, timing_files, fsl_contrast_ids, contrast_values = \</li><li>            read_design_fsl_design_file(design_file)</li><li>        print "... done.\r\n"</li><li></li><li>        # fix timing filenames</li><li>        timing_files = _insert_directory_in_file_name(</li><li>            timing_files, "tfMRI_%s_%s" % (task_id, direction), 1)</li><li></li><li>        # make design matrix</li><li>        print "Constructing design matrix for direction %s ..." % direction</li><li>        _n_scans = nibabel.load(fmri_files[direction_index]).shape[-1]</li><li>        n_scans.append(_n_scans)</li><li>        design_matrix, paradigm, frametimes = make_dmtx_from_timing_files(</li><li>            timing_files, fsl_condition_ids, n_scans=_n_scans, tr=tr,</li><li>            hrf_model=hrf_model, drift_model=drift_model, hfcut=hfcut,</li><li>            add_regs_file=add_regs_files[</li><li>                direction_index] if not add_regs_files is None else None,</li><li>            add_reg_names=[</li><li>                'Translation along x axis',</li><li>                'Translation along yaxis',</li><li>                'Translation along z axis',</li><li>                'Rotation along x axis',</li><li>                'Rotation along y axis',</li><li>                'Rotation along z axis',</li><li>                'Differential Translation along x axis',</li><li>                'Differential Translation along yaxis',</li><li>                'Differential Translation along z axis',</li><li>                'Differential Rotation along x axis',</li><li>                'Differential Rotation along y axis',</li><li>                'Differential Rotation along z axis'</li><li>                ][:n_motion_regressions] if not add_regs_files is None</li><li>            else None,</li><li>            )</li><li>        print "... done."</li><li></li><li>        paradigms.append(paradigm)</li><li>        frametimes_list.append(frametimes)</li><li>        design_matrices.append(design_matrix)</li><li></li><li>        # convert contrasts to dict</li><li>        contrasts = dict((contrast_id,</li><li>                          # append zeros to end of contrast to match design</li><li>                          np.hstack((contrast_value, np.zeros(len(</li><li>                                design_matrix.names) - len(contrast_value)))))</li><li></li><li>                         for contrast_id, contrast_value in zip(</li><li>                fsl_contrast_ids, contrast_values))</li><li></li><li>        # more interesting contrasts</li><li>        if task_id == 'MOTOR':</li><li>            contrasts['RH-LH'] = contrasts['RH'] - contrasts['LH']</li><li>            contrasts['LH-RH'] = -contrasts['RH-LH']</li><li>            contrasts['RF-LF'] = contrasts['RF'] - contrasts['LF']</li><li>            contrasts['LF-RF'] = -contrasts['RF-LF']</li><li>            contrasts['H'] = contrasts['RH'] + contrasts['LH']</li><li>            contrasts['F'] = contrasts['RF'] + contrasts['LF']</li><li>            contrasts['H-F'] = contrasts['RH'] + contrasts['LH'] - (</li><li>                contrasts['RF'] - contrasts['LF'])</li><li>            contrasts['F-H'] = -contrasts['H-F']</li><li></li><li>    # importat maps</li><li>    z_maps = {}</li><li>    effects_maps = {}</li><li></li><li>    # replicate contrasts across sessions</li><li>    contrasts = dict((cid, [cval] * 2)</li><li>                     for cid, cval in contrasts.iteritems())</li><li></li><li>    # compute effects</li><li>    mask_path = os.path.join(subject_output_dir, "mask.nii.gz")</li><li>    skip = os.path.isfile(mask_path)</li><li>    if skip:</li><li>        for contrast_id, contrast_val in contrasts.iteritems():</li><li>            for map_type in ['z', 'effects']:</li><li>                map_dir = os.path.join(</li><li>                    subject_output_dir, '%s_maps' % map_type)</li><li>                if not os.path.exists(map_dir):</li><li>                    os.makedirs(map_dir)</li><li>                map_path = os.path.join(</li><li>                    map_dir, '%s.nii.gz' % contrast_id)</li><li>                if not os.path.exists(map_path):</li><li>                    skip = 0</li><li>                    break</li><li></li><li>                # collect zmaps for contrasts we're interested in</li><li>                if map_type == 'z':</li><li>                    z_maps[contrast_id] = map_path</li><li></li><li>                if map_type == 'effects':</li><li>                    effects_maps[contrast_id] = map_path</li><li></li><li>            if skip:</li><li>                print "Skipping subject %s..." % (</li><li>                    subject_id)</li><li></li><li>    # fit GLM</li><li>    if not skip:</li><li>        print (</li><li>            'Fitting a "Fixed Effect" GLM for merging LR and RL phase-encoding '</li><li>            'directions for subject %s ...' % subject_id)</li><li>        fmri_glm = FMRILinearModel(fmri_files,</li><li>                                   [design_matrix.matrix</li><li>                                    for design_matrix in design_matrices],</li><li>                                   mask='compute'</li><li>                                   )</li><li>        fmri_glm.fit(do_scaling=True, model='ar1')</li><li>        print "... done.\r\n"</li><li></li><li>        # save computed mask</li><li>        mask_path = os.path.join(subject_output_dir, "mask.nii.gz")</li><li>        print "Saving mask image to %s ..." % mask_path</li><li>        nibabel.save(fmri_glm.mask, mask_path)</li><li>        print "... done.\r\n"</li><li></li><li>        # compute effects</li><li>        for contrast_id, contrast_val in contrasts.iteritems():</li><li>            print "\tcontrast id: %s" % contrast_id</li><li>            z_map, eff_map = fmri_glm.contrast(</li><li>                contrast_val,</li><li>                con_id=contrast_id,</li><li>                output_z=True,</li><li>                output_effects=True</li><li>                )</li><li></li><li>            # store stat maps to disk</li><li>            for map_type, out_map in zip(['z', 'effects'],</li><li>                                         [z_map, eff_map]):</li><li>                map_dir = os.path.join(</li><li>                    subject_output_dir, '%s_maps' % map_type)</li><li>                if not os.path.exists(map_dir):</li><li>                    os.makedirs(map_dir)</li><li>                map_path = os.path.join(</li><li>                    map_dir, '%s.nii.gz' % contrast_id)</li><li>                print "\t\tWriting %s ..." % map_path</li><li>                nibabel.save(out_map, map_path)</li><li></li><li>                # collect zmaps for contrasts we're interested in</li><li>                if map_type == 'z':</li><li>                    z_maps[contrast_id] = map_path</li><li></li><li>                if map_type == 'effects':</li><li>                    effects_maps[contrast_id] = map_path</li><li></li><li>    # remove repeated contrasts</li><li>    contrasts = dict((cid, cval[0]) for cid, cval in contrasts.iteritems())</li><li></li><li>    # do stats report</li><li>    if 0x0:</li><li>        anat_img = load_specific_vol(fmri_files[0], 0)[0]</li><li>        stats_report_filename = os.path.join(subject_output_dir,</li><li>                                             "reports",</li><li>                                             "report_stats.html")</li><li>        generate_subject_stats_report(</li><li>            stats_report_filename,</li><li>            contrasts,</li><li>            z_maps,</li><li>            nibabel.load(mask_path),</li><li>            anat=anat_img.get_data(),</li><li>            anat_affine=anat_img.get_affine(),</li><li>            threshold=threshold,</li><li>            cluster_th=cluster_th,</li><li>            slicer=slicer,</li><li>            cut_coords=cut_coords,</li><li>            design_matrices=design_matrices,</li><li>            subject_id=subject_id,</li><li>            start_time=stats_start_time,</li><li>            title="GLM for subject %s" % subject_id,</li><li></li><li>            # additional ``kwargs`` for more informative report</li><li>            TR=tr,</li><li>            n_scans=n_scans,</li><li>            hfcut=hfcut,</li><li>            drift_model=drift_model,</li><li>            hrf_model=hrf_model,</li><li>            paradigm={'LR': paradigms[0].__dict__,</li><li>                      'RL': paradigms[1].__dict__},</li><li>            frametimes={'LR': frametimes_list[0], 'RL': frametimes_list[1]},</li><li>            fwhm=fwhm</li><li>            )</li><li></li><li>        ProgressReport().finish_dir(subject_output_dir)</li><li>        print "\r\nStatistic report written to %s\r\n" % stats_report_filename</li><li></li><li>    return contrasts, effects_maps, z_maps, mask_path</li><li></li><li>if __name__ == '__main__':</li><li>    ###########################################################################</li><li>    # CONFIGURATION</li><li>    n_jobs = int(os.environ.get('N_JOBS', -1))</li><li>    n_subjects = int(os.environ.get('N_SUBJECTS', -1))</li><li>    subject_ids = os.environ.get('SUBJECT_IDS', None)</li><li>    subject_ids = subject_ids.split(",") if not subject_ids is None else None</li><li>    task_ids = os.environ.get('TASK_IDS', ",".join(('WM',</li><li>                                                    'MOTOR,'</li><li>                                                    'LANGUAGE,'</li><li>                                                    'EMOTION,'</li><li>                                                    'GAMBLING,'</li><li>                                                    'RELATIONAL,'</li><li>                                                    'SOCIAL'</li><li>                                                    ))).split(',')</li><li>    do_preproc = os.environ.get("PREPROC", False)</li><li>    do_normalize = os.environ.get("NORMALIZE", False) and do_preproc</li><li>    fwhm = np.fromstring(os.environ.get("fwhm", "0."), sep=",")</li><li>    slicer = 'z'  # slicer of activation maps QA</li><li>    cut_coords = 5</li><li>    threshold = 3.</li><li>    cluster_th = 15  # minimum number of voxels in reported clusters</li><li></li><li>    ###########################################################################</li><li>    # DIRECTORIES</li><li>    data_dir = "/media/HCP-Q2/"</li><li>    if len(sys.argv) > 1:</li><li>        data_dir = sys.argv[1]</li><li>        assert os.path.isdir(data_dir), (</li><li>            "data_dir '%s' doesn't exist") % data_dir</li><li></li><li>    output_dir = "/volatile/home/edohmato/connectome_output"</li><li>    if len(sys.argv) > 2:</li><li>        output_dir = sys.argv[2]</li><li></li><li>    if do_preproc:</li><li>        output_dir = os.path.join(output_dir, "custom_preproc")</li><li>    else:</li><li>        output_dir = os.path.join(output_dir, "hcp_preproc")</li><li></li><li>    if not os.path.exists(output_dir):</li><li>        os.makedirs(output_dir)</li><li></li><li>    ###########################################################################</li><li>    # DATA GRABBING</li><li>    def _subject_factory(task_output_dir, n_subjects=-1):</li><li>        """</li><li>        Generator for subject data.</li><li></li><li>        Returns</li><li>        -------</li><li>        subject_data_dir: string</li><li>            existing directory; directory containing subject data</li><li>        subject_output_dir: string</li><li>            output directory for subject GLM</li><li></li><li>        """</li><li></li><li>        for subject_data_dir in sorted(glob.glob(os.path.join(</li><li>                    data_dir, "******"))):</li><li>            if n_subjects == 0:</li><li>                return</li><li>            else:</li><li>                n_subjects -= 1</li><li></li><li>            # is this a subject data dir ?</li><li>            if not (re.match("^.+?[0-9]{6}\/?$", subject_data_dir)</li><li>                    and os.path.isdir(subject_data_dir)):</li><li>                continue</li><li></li><li>            subject_id = os.path.basename(subject_data_dir)</li><li></li><li>            # if os.path.isfile(os.path.join(output_dir, task_id, subject_id,</li><li>            #                                "z_maps/LH-RH.nii.gz")):</li><li>            #     continue</li><li></li><li>            if os.path.exists(os.path.join(</li><li>                    output_dir, "%s/z_maps/LH-RH.nii.gz" % subject_id)):</li><li>                continue</li><li></li><li>            # exclude this subject ?</li><li>            if not subject_ids is None and not subject_id in subject_ids:</li><li>                print "Skipping %s ..." % subject_id</li><li>                continue</li><li></li><li>            subject_output_dir = os.path.join(task_output_dir, subject_id)</li><li></li><li>            yield subject_data_dir, subject_output_dir</li><li></li><li>    ###########################################################################</li><li>    # MAIN LOOP</li><li>    def _run_suject_level1_glm(subject_data_dir, subject_output_dir,</li><li>                               **kwargs):</li><li>        """</li><li>        Just another wrapper.</li><li></li><li>        """</li><li></li><li>        mem = Memory(os.path.join(subject_output_dir, "cache_dir"))</li><li>        return mem.cache(run_suject_level1_glm)(subject_data_dir,</li><li>                                                subject_output_dir,</li><li>                                                **kwargs)</li><li></li><li>    for task_id in task_ids:</li><li>        try:</li><li>            # best slicer for given task</li><li>            if task_id == "MOTOR":</li><li>                slicer = 'y'</li><li></li><li>            # task output dir</li><li>            task_output_dir = os.path.join(output_dir, task_id)</li><li></li><li>            # chronometry</li><li>            stats_start_time = pretty_time()</li><li></li><li>            # run intra-subject GLM and collect the results group-level GLM</li><li>            group_glm_inputs = [subject_glm_results</li><li>                                        for subject_glm_results in Parallel(</li><li>                    n_jobs=n_jobs, verbose=100)(delayed(run_suject_level1_glm)(</li><li>                        subject_data_dir,</li><li>                        subject_output_dir,</li><li>                        task_id=task_id,</li><li>                        do_preproc=do_preproc,</li><li>                        do_normalize=do_normalize,</li><li>                        fwhm=fwhm,</li><li>                        regress_motion=True,</li><li>                        slicer=slicer,</li><li>                        cut_coords=cut_coords,</li><li>                        threshold=threshold,</li><li></li><li>                        cluster_th=cluster_th</li><li>                        ) for subject_data_dir, subject_output_dir</li><li>                                                in _subject_factory(</li><li>                        task_output_dir, n_subjects=n_subjects))</li><li>                                        if not subject_glm_results is None]</li><li></li><li>            #######################################################################</li><li>            # GROUP ANALYSIS BEGINS</li><li>            if not do_preproc or (do_preproc and do_normalize):</li><li>                # compute group mask</li><li>                print "\r\nComputing group mask ..."</li><li>                mask_images = [subject_glm_results[3]</li><li>                               for subject_glm_results in group_glm_inputs]</li><li>                group_mask = nibabel.Nifti1Image(intersect_masks(mask_images</li><li>                                                               ).astype(np.uint8),</li><li>                                               nibabel.load(mask_images[0]</li><li>                                                            ).get_affine())</li><li>                print "... done.\r\n"</li><li>                print "Group GLM"</li><li>                contrasts = [</li><li>                    subject_glm_results</li><li>                    for subject_glm_results in group_glm_inputs]</li><li>                contrasts = group_glm_inputs[0][0]</li><li>                sujects_effects_maps = [subject_glm_results[1]</li><li>                                       for subject_glm_results in group_glm_inputs]</li><li>                group_level_z_maps = {}</li><li>                design_matrix = np.ones(len(sujects_effects_maps)</li><li>                                        )[:, np.newaxis]  # only the intercept</li><li>                for contrast_id in contrasts:</li><li>                    print "\tcontrast id: %s" % contrast_id</li><li></li><li>                    # effects maps will be the input to the second level GLM</li><li>                    first_level_image = nibabel.concat_images(</li><li>                        [x[contrast_id] for x in sujects_effects_maps])</li><li></li><li>                    # fit 2nd level GLM for given contrast</li><li>                    group_model = FMRILinearModel(first_level_image,</li><li>                                                design_matrix, group_mask)</li><li>                    group_model.fit(do_scaling=False, model='ols')</li><li></li><li>                    # specify and estimate the contrast</li><li>                    contrast_val = np.array(([[1.]])</li><li>                                            )  # the only possible contrast !</li><li>                    z_map, = group_model.contrast(</li><li>                        contrast_val,</li><li>                        con_id='one_sample %s' % contrast_id,</li><li>                        output_z=True)</li><li></li><li>                    # save map</li><li>                    map_dir = os.path.join(task_output_dir, 'z_maps')</li><li>                    if not os.path.exists(map_dir):</li><li>                        os.makedirs(map_dir)</li><li>                    map_path = os.path.join(map_dir, '2nd_level_%s.nii.gz' % (</li><li>                            contrast_id))</li><li>                    print "\t\tWriting %s ..." % map_path</li><li>                    nibabel.save(z_map, map_path)</li><li></li><li>                    group_level_z_maps[contrast_id] = map_path</li><li></li><li>                # do stats report</li><li>                stats_report_filename = os.path.join(task_output_dir, "reports",</li><li>                                                     "report_stats.html")</li><li>                generate_subject_stats_report(</li><li>                    stats_report_filename,</li><li>                    contrasts,</li><li>                    group_level_z_maps,</li><li>                    group_mask,</li><li>                    threshold=threshold,</li><li>                    cluster_th=cluster_th,</li><li>                    design_matrices=[design_matrix],</li><li>                    subject_id="sub001",</li><li>                    start_time=stats_start_time,</li><li>                    title='Group GLM for HCP fMRI %s task' % task_id,</li><li>                    slicer=slicer,</li><li>                    cut_coords=cut_coords</li><li>                    )</li><li></li><li>                ProgressReport().finish_dir(task_output_dir)</li><li>                print "\r\nStatistic report written to %s\r\n" % (</li><li>                    stats_report_filename)</li><li>        except Exception, e:</li><li>            print e</li><li></li><li></li><li></li></pre></ol></code>
    </div>

    <br/>References<br/><br/>
      <ul>
	<li>Russel A. Poldrack et al. <i>Handbook of Functional MRI Data Analysis</i></li>
	<li>F. Gregory Ashby. <i>Statistical Analysis of fMRI Data</i></li>
      </ul>
    <br clear="all"/>   
    <hr/>

    <script type="text/javascript">
      $('#design').load("design.html").fadeIn("slow");
    </script>
    <b>Experimental design</b><br/><br/>
    The following control parameters were used for   specifying the experimental paradigm and fitting the GLM:<br/><ul><li>contrasts: <ul><li>MATH-STORY: <ul type="none"><li>[1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</li></ul></li><li>neg_STORY: <ul type="none"><li>[0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</li></ul></li><li>STORY: <ul type="none"><li>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</li></ul></li><li>STORY-MATH: <ul type="none"><li>[-1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</li></ul></li><li>MATH: <ul type="none"><li>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</li></ul></li><li>neg_MATH: <ul type="none"><li>[-1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</li></ul></li></ul></li></ul>
    <div id="design">
    </div>
    <br clear="all"/>
    <hr/>
    
    <script type="text/javascript">
      $('#activation').load("activation.html").fadeIn("slow");
    </script>
    <b>Thresholded activation maps (threshold = 3.0)</b><br/><br/>
    Below are thresholded activation z-maps (<b>cmap = "cold_hot"</b>) for the different contrasts of interest. Click on a thumbnail for more details.<br/>
    <br clear="all"/>
    <center><img src="activation_colorbar.png" /></center> <!-- centralized colorbar for activations-->
    <div id="activation">
    </div>
    <br clear="all"/>
    <hr/>

    <!-- It's time for javascript, folks -->
    <script type="text/javascript" src="./jquery.min.js"></script>
    <script type="text/javascript" src="./base.js"></script>
    <script type="text/javascript">
      $(function(){
      $('li')
      .css('pointer','default')
      .css('list-style-image','none');
      $('li:has(ul)')
      .click(function(event){
      if (this == event.target) {
      $(this).css('list-style-image',
      (!$(this).children().is(':hidden')) ? 'url(plusbox.gif)' : 'url(minusbox.gif)');
      $(this).children().toggle('slow');
      }
      return false;
			})
      .css({cursor:'pointer', 'list-style-image':'url(plusbox.gif)'})
      .children().hide();
      $('li:not(:has(ul))').css({cursor:'default', 'list-style-image':'none'});
      });
      
      $(function(){
      $("#sourcecode a.sourcecodeanchor").click(function(){
      $(this).toggleText("View", "Hide").next().toggle();
      return false;
      });
      });

      $(document).ready(function(){
      $('#design').load("design.html").fadeIn("slow");
      $('#activation').load("activation.html").fadeIn("slow");    
      });
    </script>

  </body>
</html>
